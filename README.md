<h1 align="center">Hi ðŸ‘‹, here we have the Apache Spark laboratories supported by E.On Software Development</h1>
<h3 align="center">Developed and familiar with PySpark, the Python API for Apache Spark!</h3>

## Table Of Content
* [About The Course](#course)
* [Phases Of Learning](#learn)

--------------------------------------------------------------------------------

<h1 id="course" align="left">About The Course:</h1>

<h3 align="left">The description:</h3>

EN: This course provides an accessible introduction to big data analytics using the Apache Spark analytics engine. It is ideal for those who want to better understand how to process and analyze large volumes of data, providing a balance between theory and practice, with concrete industry examples. Perfect for anyone who wants to improve their data analytics skills, regardless of previous experience.

RO: Acest curs oferÄƒ o introducere accesibilÄƒ Ã®n analiza bazelor de date mari folosind motorul de analizÄƒ Apache Spark. Este ideal pentru cei care vor sÄƒ Ã®nÈ›eleagÄƒ mai bine cum se proceseazÄƒ È™i se analizeazÄƒ volume mari de date, oferind un echilibru Ã®ntre teorie È™i practicÄƒ, cu exemple concrete din industrie. Perfect pentru oricine vrea sÄƒ-È™i Ã®mbunÄƒtÄƒÈ›eascÄƒ abilitÄƒÈ›ile Ã®n analiza datelor, indiferent de nivelul de experienÈ›Äƒ anterior.

---

<h3 align="left">The General Objective:</h3>

EN: Knowledge and effective application of PySpark knowledge for fundamental Data Engineering problems

RO: CunoaÈ™terea È™i aplicarea eficientÄƒ a cunoÈ™tinÈ›elor de PySpark pentru probleme fundamentale de Data Engineering

---

<h3 align="left">The Specific Objectives:</h3>

EN: 

- Designing the data transformation and aggregation process to solve the Data Engineering problem.

- Explaining and justifying the operations used.

- Ability to choose the most appropriate operation depending on the case.

- Visualizing the data and its results.
  
RO:

- Proiectarea procesului de transformare È™i agregare a datelor pentru rezolvarea problemei de Data Engineering.

- Explicarea È™i justificarea operaÈ›iilor folosite.
    
- Abilitatea de a alege cea mai potrivitÄƒ operaÈ›ie Ã®n funcÈ›ie de caz.
    
- Vizualizarea datelor È™i rezultatele acestora.

* [Table Of Content](#table-of-content)

---

<h1 id="learn" align="left">Phases Of Learning:</h1>
 
| Notebook | Description |
|----------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Laboratory_1](http://nbviewer.ipython.org/github/AndromedaOMA/Advanced_Analytics_with_Apache_Spark---E.On_Software_Development/blob/main/Laboratory_1.ipynb) | Understanding the basic concepts of working with Data Frames within the PySpark library. |
| [Laboratory_2](http://nbviewer.ipython.org/github/AndromedaOMA/Advanced_Analytics_with_Apache_Spark---E.On_Software_Development/blob/main/Laboratory_2.ipynb) | Deepening the methods and (chained) expressions of transformation, filtering and sorting. |
| [Laboratory_3](http://nbviewer.ipython.org/github/AndromedaOMA/Advanced_Analytics_with_Apache_Spark---E.On_Software_Development/blob/main/Laboratory_3.ipynb) | Deepening the notions of grouping, aggregation and union, respectively data association. Plus an introduction to the MLLib library. |
| [Laboratory_4](http://nbviewer.ipython.org/github/AndromedaOMA/Advanced_Analytics_with_Apache_Spark---E.On_Software_Development/blob/main/Laboratory_3.ipynb) | Familiarization with Spark Core and its utilities. Plus an extension thepry for MLLib that include the advanced topics like models training. |
| [Final_Project](http://nbviewer.ipython.org/github/AndromedaOMA/Advanced_Analytics_with_Apache_Spark---E.On_Software_Development/blob/main/Final_Project.ipynb) | This project has as its main goal the analysis of the energy consumption of a group of fictitious consumers, over the course of a year, of an energy company, using the analysis techniques of the Apache Spark engine. |

* [Table Of Content](#table-of-content)

---

- âš¡ Fun fact: **Through this project I developed better the subtle concepts of Data Science using PySpark!**
