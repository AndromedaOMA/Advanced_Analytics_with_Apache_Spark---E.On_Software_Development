{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKbsVFnLK9PFrN8avzOeFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndromedaOMA/Advanced_Analytics_with_Apache_Spark---E.On_Software_Development/blob/main/Laboratory_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregătire mediu de lucru\n"
      ],
      "metadata": {
        "id": "hjU9wHFbxdV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NR2CQBShxRMv",
        "outputId": "2409d6ba-0f26-416b-e431-b00f8d549399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "m2MQf9FTZ0_m",
        "outputId": "b693487f-28d1-4a5f-89d2-9634a74f816b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [1 InRelease 14.2 kB/129\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to cloud.r-pr\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.138.128.44)] [C\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.\u001b[0m\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [73.0 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,697 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,847 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,101 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,161 kB]\n",
            "Fetched 24.7 MB in 9s (2,899 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d7b07a905d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://338978dbc171:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://dlcdn.apache.org/spark/\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.4/spark-3.4.4-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.4-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.4-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as f\n",
        "spark= SparkSession.builder.getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Înlănțuirea metodelor"
      ],
      "metadata": {
        "id": "4XZeJUFwwWJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Java Builder\n",
        "\n",
        "În programarea orientată obiect (OOP), design pattern-urile sunt șabloane pentru a rezolva probleme comune de\n",
        "design a software-ului. Unul dintre cele mai cunoscute design pattern-uri este Builder, provenit din limbajul Java."
      ],
      "metadata": {
        "id": "V_6BD5pC8WRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementarea șablonului și în Python:"
      ],
      "metadata": {
        "id": "VQqOZ9Rz9ePB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CarBuilder:\n",
        "  # Inițializarea builder-ului cu valori implicite potrivite.\n",
        "  def __init__(self):\n",
        "    self.car = {'wheels': 4, 'color': 'Silver'}\n",
        "  # Funcțiile de setare a opțiunilor. Șablonul de builder se remarcă prin returnarea obiectul de self la metodele sale de setare. Asta permite înlănțuirea metodelor:\n",
        "  def set_wheels(self, number):\n",
        "    self.car['wheels'] = number\n",
        "    return self\n",
        "  def set_color(self, color):\n",
        "    self.car['color'] = color\n",
        "    return self\n",
        "  # Funcțiile de finalizare, care returnează rezultatul\n",
        "  def build(self):\n",
        "    return self.car"
      ],
      "metadata": {
        "id": "aqpYQWvE8npC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Java Builder – Utilizare in PySpark\n",
        "\n",
        "Având la bază limbajul Scala, bazat pe Java, și fiind și un Framework bazat pe construcții de transformări, Spark, și\n",
        "respectiv PySpark, se folosesc de acest șablonul de programare Builder în API-ul pe care îl oferă."
      ],
      "metadata": {
        "id": "JcYizfhV9YRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am întâlnit până acum aceste construcții:"
      ],
      "metadata": {
        "id": "w2j6pKJk9iIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import types as T\n",
        "data_schema = T.StructType([\n",
        "T.StructField('nume', T.StringType(), False),\n",
        "T.StructField('varsta', T.IntegerType(), False),\n",
        "T.StructField('ocupatie', T.StringType(), False),\n",
        "T.StructField('vechime', T.IntegerType(), False),\n",
        "T.StructField('inactiv', T.BooleanType(), True),\n",
        "T.StructField('zona', T.StringType(), True),\n",
        "T.StructField('extra', T.ArrayType(T.StringType()), True)\n",
        "])\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').config('spark.driver.memory', '3g').getOrCreate()\n",
        "#       ---------------------======================================================______________\n",
        "# Inițializarea builder-ului|       Apelarea funcțiilor de schimbare a           | Apelarea funcției de finalizare\n",
        "# cu valori implicite       |            opțiunilor implicite.                   | care returnează obiectul\n",
        "# potrivite alese de        |                                                    | constuit Spark/Data Frame\n",
        "#         -----------===========================================================_______________________________\n",
        "data_df = spark.read.format('csv').option('header', 'true').schema(data_schema).load('/path/to/folder/or/file')"
      ],
      "metadata": {
        "id": "iNWflsly9rgq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wt-N-SgF-eGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comenzi de transformare\n",
        "\n",
        "*Ce nu trebuie, nu facem!*"
      ],
      "metadata": {
        "id": "oixti9iq_Mz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datele de test (createDataFrame)\n",
        "\n",
        "Pentru a testa cod de Spark, în general, se folosesc liste mici cu date de test la crearea unui Data Frame, în loc să\n",
        "citim datele. Când testam aplicații de Spark, putem folosi această metodă pentru scrierea de test."
      ],
      "metadata": {
        "id": "igmwg_QF_0LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "➢ Funcția **createDataFrame** ne permite să specificăm doar numele coloanelor, fără a fi nevoie să\n",
        "specificăm și tipul lor. Spark va trece prin data și va încerca să deducă automat tipul de date."
      ],
      "metadata": {
        "id": "YsnyB8Zp_kde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "['Vali', 23, 'Programator', 4, None, 'A' , ['3D Printer', 'XBOX']],\n",
        "['Vlad', 34, 'Instalator', 11, None, 'B', ['EV']],\n",
        "['Bea', 29, 'Reporter', 7, True, 'B', None]\n",
        "]\n",
        "data_df = spark.createDataFrame(data, schema=['nume', 'varsta', 'ocupatie', 'vechime', 'inactiv', 'zona', 'extra'])"
      ],
      "metadata": {
        "id": "YR2J2bpE_mPr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proiectarea Datelor - Select (select)\n",
        "\n",
        "Data Frame-urile oferă și metode pentru proiectarea datelor, pe lângă cele de scriere, colectare și afișare, similare\n",
        "cu interogările din bazele de date SQL, în același stil de apelare prin înlănțuire."
      ],
      "metadata": {
        "id": "PUdeAmv5_2yS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "➢ Operația de Selecție – Păstrarea doar anumite coloane"
      ],
      "metadata": {
        "id": "ggZsa22FAFsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df = data_df.select('nume', 'varsta', 'extra')"
      ],
      "metadata": {
        "id": "hmlzh-tmAH-y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "❖ Un nou obiect de tip Data Frame este returnat care are doar coloanele nume, varsta și extra. Data Frame-ul\n",
        "de la care a pornit proiecția va rămâne neschimbat."
      ],
      "metadata": {
        "id": "Y-W-_yf7AJRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.show()"
      ],
      "metadata": {
        "id": "NUkocdcTANB8",
        "outputId": "db42b88d-5da9-4144-9a6b-d7ec3f4f3599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+-----------+-------+-------+----+------------------+\n",
            "|nume|varsta|   ocupatie|vechime|inactiv|zona|             extra|\n",
            "+----+------+-----------+-------+-------+----+------------------+\n",
            "|Vali|    23|Programator|      4|   NULL|   A|[3D Printer, XBOX]|\n",
            "|Vlad|    34| Instalator|     11|   NULL|   B|              [EV]|\n",
            "| Bea|    29|   Reporter|      7|   true|   B|              NULL|\n",
            "+----+------+-----------+-------+-------+----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df.show()"
      ],
      "metadata": {
        "id": "E5Ywz9aBAUax",
        "outputId": "a8a11eea-163b-4558-a9fa-976b1dce3872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------------------+\n",
            "|nume|varsta|             extra|\n",
            "+----+------+------------------+\n",
            "|Vali|    23|[3D Printer, XBOX]|\n",
            "|Vlad|    34|              [EV]|\n",
            "| Bea|    29|              NULL|\n",
            "+----+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proiectarea Datelor - Ștergere (drop)\n",
        "\n",
        "De multe ori se întâmplă să lucrăm cu date care conțin foarte multe coloane, și devine inpractic să le selectăm. În\n",
        "loc de selecția coloanelor pe care dorim să le păstrăm, putem scoate coloanele de care nu avem nevoie."
      ],
      "metadata": {
        "id": "32uWop9sAY12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "➢ Operația de Ștergere – Ștergere a coloanelor"
      ],
      "metadata": {
        "id": "XUcrTBpgAjHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df = data_df.drop('varsta', 'zona', 'extra')"
      ],
      "metadata": {
        "id": "b23fAxDzAoBs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "❖ Un nou obiect de tip Data Frame este returnat care nu mai are coloanele varsta, concediu și\n",
        "extra. Data Frame-ul de la care a pornit proiecția va rămâne neschimbat."
      ],
      "metadata": {
        "id": "KhYIT8FXAq1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.show()"
      ],
      "metadata": {
        "id": "qrmDz2XTAu1d",
        "outputId": "eb734048-5ee3-47ce-e566-55248ffb214a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+-----------+-------+-------+----+------------------+\n",
            "|nume|varsta|   ocupatie|vechime|inactiv|zona|             extra|\n",
            "+----+------+-----------+-------+-------+----+------------------+\n",
            "|Vali|    23|Programator|      4|   NULL|   A|[3D Printer, XBOX]|\n",
            "|Vlad|    34| Instalator|     11|   NULL|   B|              [EV]|\n",
            "| Bea|    29|   Reporter|      7|   true|   B|              NULL|\n",
            "+----+------+-----------+-------+-------+----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df.show()"
      ],
      "metadata": {
        "id": "J-AcW9ohAxDQ",
        "outputId": "131f34cf-0974-4dba-ae97-b0cc43eb4df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-------+-------+\n",
            "|nume|   ocupatie|vechime|inactiv|\n",
            "+----+-----------+-------+-------+\n",
            "|Vali|Programator|      4|   NULL|\n",
            "|Vlad| Instalator|     11|   NULL|\n",
            "| Bea|   Reporter|      7|   true|\n",
            "+----+-----------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proiectarea Datelor – Redenumirea Coloanelor (withColumnRenamed)\n",
        "\n",
        "Numele coloanele din date adesea nu se potrivesc cu metodologia noastă de a numi coloanele, de exemplu\n",
        "conțin caractere neobișnuite sau sunt în altă limbă. Putem să redenumim aceste coloane pentru a le standardiza."
      ],
      "metadata": {
        "id": "7k5C4KQNBH0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "➢ Operația de Redenumire – Redenumire a coloanelor"
      ],
      "metadata": {
        "id": "8gHeiRL0BXtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df = data_df.withColumnRenamed('ocupatie', 'job')"
      ],
      "metadata": {
        "id": "l_NWuJDaBaix"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "❖ Un nou obiect de tip Data Frame este returnat care nu mai are coloana post, dar are o nouă coloană job cu\n",
        "aceleași valori. Data Frame-ul de la care a pornit proiecția va rămâne neschimbat."
      ],
      "metadata": {
        "id": "bE0_iAgqBd3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.printSchema()"
      ],
      "metadata": {
        "id": "M0LqoaO1BfZ6",
        "outputId": "33498d75-49a6-4588-996c-3dbdc96f31d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nume: string (nullable = true)\n",
            " |-- varsta: long (nullable = true)\n",
            " |-- ocupatie: string (nullable = true)\n",
            " |-- vechime: long (nullable = true)\n",
            " |-- inactiv: boolean (nullable = true)\n",
            " |-- zona: string (nullable = true)\n",
            " |-- extra: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df.printSchema()"
      ],
      "metadata": {
        "id": "ailDW6yoBhDr",
        "outputId": "1ff4d536-a1cf-4df7-aaae-13148fe71413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nume: string (nullable = true)\n",
            " |-- varsta: long (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- vechime: long (nullable = true)\n",
            " |-- inactiv: boolean (nullable = true)\n",
            " |-- zona: string (nullable = true)\n",
            " |-- extra: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}